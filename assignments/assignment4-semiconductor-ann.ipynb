{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "37puETfgRzzg"
   },
   "source": [
    "# MANU 465 Assignment 3 - Semiconductor Manufacturing Process Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Author:\n",
    "\n",
    "Liam Bontkes, 25530163"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Project Description\n",
    "\n",
    "This project goes builds a model to predict the status of part (Pass/Fail) from the Semiconductor Manufacturing Process\n",
    "dataset. The model will be built using the Logistic Regression method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 1.1 Background\n",
    "\n",
    "Source: https://www.kaggle.com/saurabhbagchi/fmst-semiconductor-manufacturing-project\n",
    "\n",
    "A complex modern semiconductor manufacturing process is normally under constant surveillance via the monitoring of\n",
    "signals/variables collected from sensors and or process measurement points. However, not all of these signals are\n",
    "equally valuable in a specific monitoring system. The measured signals contain a combination of useful information,\n",
    "irrelevant information as well as noise. Engineers typically have a much larger number of signals than are actually\n",
    "required. If we consider each type of signal as a feature, then feature selection may be applied to identify the most\n",
    "relevant signals. The Process Engineers may then use these signals to determine key factors contributing to yield\n",
    "excursions downstream in the process. This will enable an increase in process throughput, decreased time to learning,\n",
    "and reduce per-unit production costs. These signals can be used as features to predict the yield type. And by analyzing\n",
    "and trying out different combinations of features, essential signals that are impacting the yield type can be\n",
    "identified."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Importing the Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-24 21:15:51.310057: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-10-24 21:15:51.310074: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 3 Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RopL7tUZSQkT"
   },
   "source": [
    "### 3.1 Importing the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WwEPNDWySTKm"
   },
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('../data/SemiconductorManufacturingProcess.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Showing the Dataset in a Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>Sensor 1</th>\n",
       "      <th>Sensor 2</th>\n",
       "      <th>Sensor 3</th>\n",
       "      <th>Sensor 4</th>\n",
       "      <th>Sensor 5</th>\n",
       "      <th>Sensor 6</th>\n",
       "      <th>Sensor 7</th>\n",
       "      <th>Sensor 8</th>\n",
       "      <th>Sensor 9</th>\n",
       "      <th>...</th>\n",
       "      <th>Sensor 429</th>\n",
       "      <th>Sensor 430</th>\n",
       "      <th>Sensor 431</th>\n",
       "      <th>Sensor 432</th>\n",
       "      <th>Sensor 433</th>\n",
       "      <th>Sensor 434</th>\n",
       "      <th>Sensor 435</th>\n",
       "      <th>Sensor 436</th>\n",
       "      <th>Sensor 437</th>\n",
       "      <th>Pass/Fail</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7/19/2008 11:55</td>\n",
       "      <td>3030.93</td>\n",
       "      <td>2564.00</td>\n",
       "      <td>2187.7333</td>\n",
       "      <td>1411.1265</td>\n",
       "      <td>1.3602</td>\n",
       "      <td>97.6133</td>\n",
       "      <td>0.1242</td>\n",
       "      <td>1.5005</td>\n",
       "      <td>0.0162</td>\n",
       "      <td>...</td>\n",
       "      <td>14.9509</td>\n",
       "      <td>0.5005</td>\n",
       "      <td>0.0118</td>\n",
       "      <td>0.0035</td>\n",
       "      <td>2.3630</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7/19/2008 12:32</td>\n",
       "      <td>3095.78</td>\n",
       "      <td>2465.14</td>\n",
       "      <td>2230.4222</td>\n",
       "      <td>1463.6606</td>\n",
       "      <td>0.8294</td>\n",
       "      <td>102.3433</td>\n",
       "      <td>0.1247</td>\n",
       "      <td>1.4966</td>\n",
       "      <td>-0.0005</td>\n",
       "      <td>...</td>\n",
       "      <td>10.9003</td>\n",
       "      <td>0.5019</td>\n",
       "      <td>0.0223</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>4.4447</td>\n",
       "      <td>0.0096</td>\n",
       "      <td>0.0201</td>\n",
       "      <td>0.0060</td>\n",
       "      <td>208.2045</td>\n",
       "      <td>Pass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7/19/2008 13:17</td>\n",
       "      <td>2932.61</td>\n",
       "      <td>2559.94</td>\n",
       "      <td>2186.4111</td>\n",
       "      <td>1698.0172</td>\n",
       "      <td>1.5102</td>\n",
       "      <td>95.4878</td>\n",
       "      <td>0.1241</td>\n",
       "      <td>1.4436</td>\n",
       "      <td>0.0041</td>\n",
       "      <td>...</td>\n",
       "      <td>9.2721</td>\n",
       "      <td>0.4958</td>\n",
       "      <td>0.0157</td>\n",
       "      <td>0.0039</td>\n",
       "      <td>3.1745</td>\n",
       "      <td>0.0584</td>\n",
       "      <td>0.0484</td>\n",
       "      <td>0.0148</td>\n",
       "      <td>82.8602</td>\n",
       "      <td>Fail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7/19/2008 14:43</td>\n",
       "      <td>2988.72</td>\n",
       "      <td>2479.90</td>\n",
       "      <td>2199.0333</td>\n",
       "      <td>909.7926</td>\n",
       "      <td>1.3204</td>\n",
       "      <td>104.2367</td>\n",
       "      <td>0.1217</td>\n",
       "      <td>1.4882</td>\n",
       "      <td>-0.0124</td>\n",
       "      <td>...</td>\n",
       "      <td>8.5831</td>\n",
       "      <td>0.4990</td>\n",
       "      <td>0.0103</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>2.0544</td>\n",
       "      <td>0.0202</td>\n",
       "      <td>0.0149</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>73.8432</td>\n",
       "      <td>Pass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7/19/2008 15:22</td>\n",
       "      <td>3032.24</td>\n",
       "      <td>2502.87</td>\n",
       "      <td>2233.3667</td>\n",
       "      <td>1326.5200</td>\n",
       "      <td>1.5334</td>\n",
       "      <td>100.3967</td>\n",
       "      <td>0.1235</td>\n",
       "      <td>1.5031</td>\n",
       "      <td>-0.0031</td>\n",
       "      <td>...</td>\n",
       "      <td>10.9698</td>\n",
       "      <td>0.4800</td>\n",
       "      <td>0.4766</td>\n",
       "      <td>0.1045</td>\n",
       "      <td>99.3032</td>\n",
       "      <td>0.0202</td>\n",
       "      <td>0.0149</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>73.8432</td>\n",
       "      <td>Pass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1562</th>\n",
       "      <td>10/16/2008 15:13</td>\n",
       "      <td>2899.41</td>\n",
       "      <td>2464.36</td>\n",
       "      <td>2179.7333</td>\n",
       "      <td>3085.3781</td>\n",
       "      <td>1.4843</td>\n",
       "      <td>82.2467</td>\n",
       "      <td>0.1248</td>\n",
       "      <td>1.3424</td>\n",
       "      <td>-0.0045</td>\n",
       "      <td>...</td>\n",
       "      <td>11.7256</td>\n",
       "      <td>0.4988</td>\n",
       "      <td>0.0143</td>\n",
       "      <td>0.0039</td>\n",
       "      <td>2.8669</td>\n",
       "      <td>0.0068</td>\n",
       "      <td>0.0138</td>\n",
       "      <td>0.0047</td>\n",
       "      <td>203.1720</td>\n",
       "      <td>Pass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1563</th>\n",
       "      <td>10/16/2008 20:49</td>\n",
       "      <td>3052.31</td>\n",
       "      <td>2522.55</td>\n",
       "      <td>2198.5667</td>\n",
       "      <td>1124.6595</td>\n",
       "      <td>0.8763</td>\n",
       "      <td>98.4689</td>\n",
       "      <td>0.1205</td>\n",
       "      <td>1.4333</td>\n",
       "      <td>-0.0061</td>\n",
       "      <td>...</td>\n",
       "      <td>17.8379</td>\n",
       "      <td>0.4975</td>\n",
       "      <td>0.0131</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>2.6238</td>\n",
       "      <td>0.0068</td>\n",
       "      <td>0.0138</td>\n",
       "      <td>0.0047</td>\n",
       "      <td>203.1720</td>\n",
       "      <td>Pass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1564</th>\n",
       "      <td>10/17/2008 5:26</td>\n",
       "      <td>2978.81</td>\n",
       "      <td>2379.78</td>\n",
       "      <td>2206.3000</td>\n",
       "      <td>1110.4967</td>\n",
       "      <td>0.8236</td>\n",
       "      <td>99.4122</td>\n",
       "      <td>0.1208</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>17.7267</td>\n",
       "      <td>0.4987</td>\n",
       "      <td>0.0153</td>\n",
       "      <td>0.0041</td>\n",
       "      <td>3.0590</td>\n",
       "      <td>0.0197</td>\n",
       "      <td>0.0086</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>43.5231</td>\n",
       "      <td>Pass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1565</th>\n",
       "      <td>10/17/2008 6:01</td>\n",
       "      <td>2894.92</td>\n",
       "      <td>2532.01</td>\n",
       "      <td>2177.0333</td>\n",
       "      <td>1183.7287</td>\n",
       "      <td>1.5726</td>\n",
       "      <td>98.7978</td>\n",
       "      <td>0.1213</td>\n",
       "      <td>1.4622</td>\n",
       "      <td>-0.0072</td>\n",
       "      <td>...</td>\n",
       "      <td>19.2104</td>\n",
       "      <td>0.5004</td>\n",
       "      <td>0.0178</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>3.5662</td>\n",
       "      <td>0.0262</td>\n",
       "      <td>0.0245</td>\n",
       "      <td>0.0075</td>\n",
       "      <td>93.4941</td>\n",
       "      <td>Pass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1566</th>\n",
       "      <td>10/17/2008 6:07</td>\n",
       "      <td>2944.92</td>\n",
       "      <td>2450.76</td>\n",
       "      <td>2195.4444</td>\n",
       "      <td>2914.1792</td>\n",
       "      <td>1.5978</td>\n",
       "      <td>85.1011</td>\n",
       "      <td>0.1235</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>22.9183</td>\n",
       "      <td>0.4987</td>\n",
       "      <td>0.0181</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>3.6275</td>\n",
       "      <td>0.0117</td>\n",
       "      <td>0.0162</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>137.7844</td>\n",
       "      <td>Pass</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1567 rows × 439 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Time  Sensor 1  Sensor 2   Sensor 3   Sensor 4  Sensor 5  \\\n",
       "0      7/19/2008 11:55   3030.93   2564.00  2187.7333  1411.1265    1.3602   \n",
       "1      7/19/2008 12:32   3095.78   2465.14  2230.4222  1463.6606    0.8294   \n",
       "2      7/19/2008 13:17   2932.61   2559.94  2186.4111  1698.0172    1.5102   \n",
       "3      7/19/2008 14:43   2988.72   2479.90  2199.0333   909.7926    1.3204   \n",
       "4      7/19/2008 15:22   3032.24   2502.87  2233.3667  1326.5200    1.5334   \n",
       "...                ...       ...       ...        ...        ...       ...   \n",
       "1562  10/16/2008 15:13   2899.41   2464.36  2179.7333  3085.3781    1.4843   \n",
       "1563  10/16/2008 20:49   3052.31   2522.55  2198.5667  1124.6595    0.8763   \n",
       "1564   10/17/2008 5:26   2978.81   2379.78  2206.3000  1110.4967    0.8236   \n",
       "1565   10/17/2008 6:01   2894.92   2532.01  2177.0333  1183.7287    1.5726   \n",
       "1566   10/17/2008 6:07   2944.92   2450.76  2195.4444  2914.1792    1.5978   \n",
       "\n",
       "      Sensor 6  Sensor 7  Sensor 8  Sensor 9  ...  Sensor 429  Sensor 430  \\\n",
       "0      97.6133    0.1242    1.5005    0.0162  ...     14.9509      0.5005   \n",
       "1     102.3433    0.1247    1.4966   -0.0005  ...     10.9003      0.5019   \n",
       "2      95.4878    0.1241    1.4436    0.0041  ...      9.2721      0.4958   \n",
       "3     104.2367    0.1217    1.4882   -0.0124  ...      8.5831      0.4990   \n",
       "4     100.3967    0.1235    1.5031   -0.0031  ...     10.9698      0.4800   \n",
       "...        ...       ...       ...       ...  ...         ...         ...   \n",
       "1562   82.2467    0.1248    1.3424   -0.0045  ...     11.7256      0.4988   \n",
       "1563   98.4689    0.1205    1.4333   -0.0061  ...     17.8379      0.4975   \n",
       "1564   99.4122    0.1208       NaN       NaN  ...     17.7267      0.4987   \n",
       "1565   98.7978    0.1213    1.4622   -0.0072  ...     19.2104      0.5004   \n",
       "1566   85.1011    0.1235       NaN       NaN  ...     22.9183      0.4987   \n",
       "\n",
       "      Sensor 431  Sensor 432  Sensor 433  Sensor 434  Sensor 435  Sensor 436  \\\n",
       "0         0.0118      0.0035      2.3630         NaN         NaN         NaN   \n",
       "1         0.0223      0.0055      4.4447      0.0096      0.0201      0.0060   \n",
       "2         0.0157      0.0039      3.1745      0.0584      0.0484      0.0148   \n",
       "3         0.0103      0.0025      2.0544      0.0202      0.0149      0.0044   \n",
       "4         0.4766      0.1045     99.3032      0.0202      0.0149      0.0044   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "1562      0.0143      0.0039      2.8669      0.0068      0.0138      0.0047   \n",
       "1563      0.0131      0.0036      2.6238      0.0068      0.0138      0.0047   \n",
       "1564      0.0153      0.0041      3.0590      0.0197      0.0086      0.0025   \n",
       "1565      0.0178      0.0038      3.5662      0.0262      0.0245      0.0075   \n",
       "1566      0.0181      0.0040      3.6275      0.0117      0.0162      0.0045   \n",
       "\n",
       "      Sensor 437  Pass/Fail  \n",
       "0            NaN       Pass  \n",
       "1       208.2045       Pass  \n",
       "2        82.8602       Fail  \n",
       "3        73.8432       Pass  \n",
       "4        73.8432       Pass  \n",
       "...          ...        ...  \n",
       "1562    203.1720       Pass  \n",
       "1563    203.1720       Pass  \n",
       "1564     43.5231       Pass  \n",
       "1565     93.4941       Pass  \n",
       "1566    137.7844       Pass  \n",
       "\n",
       "[1567 rows x 439 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 A Quick Review of the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1567 entries, 0 to 1566\n",
      "Columns: 439 entries, Time to Pass/Fail\n",
      "dtypes: float64(437), object(2)\n",
      "memory usage: 5.2+ MB\n"
     ]
    }
   ],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Separate The Input and Output\n",
    "Here, we put the independent variables in X and the dependent variable in y. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.iloc[:, 1:438].values\n",
    "y = dataset.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4.1 Showing the Input Data in a Table format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 188
    },
    "colab_type": "code",
    "id": "hCsz2yCebe1R",
    "outputId": "1e4cc568-4e51-4b38-9d46-4aa3f15204be"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>427</th>\n",
       "      <th>428</th>\n",
       "      <th>429</th>\n",
       "      <th>430</th>\n",
       "      <th>431</th>\n",
       "      <th>432</th>\n",
       "      <th>433</th>\n",
       "      <th>434</th>\n",
       "      <th>435</th>\n",
       "      <th>436</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3030.93</td>\n",
       "      <td>2564.00</td>\n",
       "      <td>2187.7333</td>\n",
       "      <td>1411.1265</td>\n",
       "      <td>1.3602</td>\n",
       "      <td>97.6133</td>\n",
       "      <td>0.1242</td>\n",
       "      <td>1.5005</td>\n",
       "      <td>0.0162</td>\n",
       "      <td>-0.0034</td>\n",
       "      <td>...</td>\n",
       "      <td>1.6765</td>\n",
       "      <td>14.9509</td>\n",
       "      <td>0.5005</td>\n",
       "      <td>0.0118</td>\n",
       "      <td>0.0035</td>\n",
       "      <td>2.3630</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3095.78</td>\n",
       "      <td>2465.14</td>\n",
       "      <td>2230.4222</td>\n",
       "      <td>1463.6606</td>\n",
       "      <td>0.8294</td>\n",
       "      <td>102.3433</td>\n",
       "      <td>0.1247</td>\n",
       "      <td>1.4966</td>\n",
       "      <td>-0.0005</td>\n",
       "      <td>-0.0148</td>\n",
       "      <td>...</td>\n",
       "      <td>1.1065</td>\n",
       "      <td>10.9003</td>\n",
       "      <td>0.5019</td>\n",
       "      <td>0.0223</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>4.4447</td>\n",
       "      <td>0.0096</td>\n",
       "      <td>0.0201</td>\n",
       "      <td>0.0060</td>\n",
       "      <td>208.2045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2932.61</td>\n",
       "      <td>2559.94</td>\n",
       "      <td>2186.4111</td>\n",
       "      <td>1698.0172</td>\n",
       "      <td>1.5102</td>\n",
       "      <td>95.4878</td>\n",
       "      <td>0.1241</td>\n",
       "      <td>1.4436</td>\n",
       "      <td>0.0041</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0952</td>\n",
       "      <td>9.2721</td>\n",
       "      <td>0.4958</td>\n",
       "      <td>0.0157</td>\n",
       "      <td>0.0039</td>\n",
       "      <td>3.1745</td>\n",
       "      <td>0.0584</td>\n",
       "      <td>0.0484</td>\n",
       "      <td>0.0148</td>\n",
       "      <td>82.8602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2988.72</td>\n",
       "      <td>2479.90</td>\n",
       "      <td>2199.0333</td>\n",
       "      <td>909.7926</td>\n",
       "      <td>1.3204</td>\n",
       "      <td>104.2367</td>\n",
       "      <td>0.1217</td>\n",
       "      <td>1.4882</td>\n",
       "      <td>-0.0124</td>\n",
       "      <td>-0.0033</td>\n",
       "      <td>...</td>\n",
       "      <td>1.7585</td>\n",
       "      <td>8.5831</td>\n",
       "      <td>0.4990</td>\n",
       "      <td>0.0103</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>2.0544</td>\n",
       "      <td>0.0202</td>\n",
       "      <td>0.0149</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>73.8432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3032.24</td>\n",
       "      <td>2502.87</td>\n",
       "      <td>2233.3667</td>\n",
       "      <td>1326.5200</td>\n",
       "      <td>1.5334</td>\n",
       "      <td>100.3967</td>\n",
       "      <td>0.1235</td>\n",
       "      <td>1.5031</td>\n",
       "      <td>-0.0031</td>\n",
       "      <td>-0.0072</td>\n",
       "      <td>...</td>\n",
       "      <td>1.6597</td>\n",
       "      <td>10.9698</td>\n",
       "      <td>0.4800</td>\n",
       "      <td>0.4766</td>\n",
       "      <td>0.1045</td>\n",
       "      <td>99.3032</td>\n",
       "      <td>0.0202</td>\n",
       "      <td>0.0149</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>73.8432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1562</th>\n",
       "      <td>2899.41</td>\n",
       "      <td>2464.36</td>\n",
       "      <td>2179.7333</td>\n",
       "      <td>3085.3781</td>\n",
       "      <td>1.4843</td>\n",
       "      <td>82.2467</td>\n",
       "      <td>0.1248</td>\n",
       "      <td>1.3424</td>\n",
       "      <td>-0.0045</td>\n",
       "      <td>-0.0057</td>\n",
       "      <td>...</td>\n",
       "      <td>1.4879</td>\n",
       "      <td>11.7256</td>\n",
       "      <td>0.4988</td>\n",
       "      <td>0.0143</td>\n",
       "      <td>0.0039</td>\n",
       "      <td>2.8669</td>\n",
       "      <td>0.0068</td>\n",
       "      <td>0.0138</td>\n",
       "      <td>0.0047</td>\n",
       "      <td>203.1720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1563</th>\n",
       "      <td>3052.31</td>\n",
       "      <td>2522.55</td>\n",
       "      <td>2198.5667</td>\n",
       "      <td>1124.6595</td>\n",
       "      <td>0.8763</td>\n",
       "      <td>98.4689</td>\n",
       "      <td>0.1205</td>\n",
       "      <td>1.4333</td>\n",
       "      <td>-0.0061</td>\n",
       "      <td>-0.0093</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0187</td>\n",
       "      <td>17.8379</td>\n",
       "      <td>0.4975</td>\n",
       "      <td>0.0131</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>2.6238</td>\n",
       "      <td>0.0068</td>\n",
       "      <td>0.0138</td>\n",
       "      <td>0.0047</td>\n",
       "      <td>203.1720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1564</th>\n",
       "      <td>2978.81</td>\n",
       "      <td>2379.78</td>\n",
       "      <td>2206.3000</td>\n",
       "      <td>1110.4967</td>\n",
       "      <td>0.8236</td>\n",
       "      <td>99.4122</td>\n",
       "      <td>0.1208</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.2237</td>\n",
       "      <td>17.7267</td>\n",
       "      <td>0.4987</td>\n",
       "      <td>0.0153</td>\n",
       "      <td>0.0041</td>\n",
       "      <td>3.0590</td>\n",
       "      <td>0.0197</td>\n",
       "      <td>0.0086</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>43.5231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1565</th>\n",
       "      <td>2894.92</td>\n",
       "      <td>2532.01</td>\n",
       "      <td>2177.0333</td>\n",
       "      <td>1183.7287</td>\n",
       "      <td>1.5726</td>\n",
       "      <td>98.7978</td>\n",
       "      <td>0.1213</td>\n",
       "      <td>1.4622</td>\n",
       "      <td>-0.0072</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>...</td>\n",
       "      <td>1.7085</td>\n",
       "      <td>19.2104</td>\n",
       "      <td>0.5004</td>\n",
       "      <td>0.0178</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>3.5662</td>\n",
       "      <td>0.0262</td>\n",
       "      <td>0.0245</td>\n",
       "      <td>0.0075</td>\n",
       "      <td>93.4941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1566</th>\n",
       "      <td>2944.92</td>\n",
       "      <td>2450.76</td>\n",
       "      <td>2195.4444</td>\n",
       "      <td>2914.1792</td>\n",
       "      <td>1.5978</td>\n",
       "      <td>85.1011</td>\n",
       "      <td>0.1235</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.2878</td>\n",
       "      <td>22.9183</td>\n",
       "      <td>0.4987</td>\n",
       "      <td>0.0181</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>3.6275</td>\n",
       "      <td>0.0117</td>\n",
       "      <td>0.0162</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>137.7844</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1567 rows × 437 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0        1          2          3       4         5       6    \\\n",
       "0     3030.93  2564.00  2187.7333  1411.1265  1.3602   97.6133  0.1242   \n",
       "1     3095.78  2465.14  2230.4222  1463.6606  0.8294  102.3433  0.1247   \n",
       "2     2932.61  2559.94  2186.4111  1698.0172  1.5102   95.4878  0.1241   \n",
       "3     2988.72  2479.90  2199.0333   909.7926  1.3204  104.2367  0.1217   \n",
       "4     3032.24  2502.87  2233.3667  1326.5200  1.5334  100.3967  0.1235   \n",
       "...       ...      ...        ...        ...     ...       ...     ...   \n",
       "1562  2899.41  2464.36  2179.7333  3085.3781  1.4843   82.2467  0.1248   \n",
       "1563  3052.31  2522.55  2198.5667  1124.6595  0.8763   98.4689  0.1205   \n",
       "1564  2978.81  2379.78  2206.3000  1110.4967  0.8236   99.4122  0.1208   \n",
       "1565  2894.92  2532.01  2177.0333  1183.7287  1.5726   98.7978  0.1213   \n",
       "1566  2944.92  2450.76  2195.4444  2914.1792  1.5978   85.1011  0.1235   \n",
       "\n",
       "         7       8       9    ...     427      428     429     430     431  \\\n",
       "0     1.5005  0.0162 -0.0034  ...  1.6765  14.9509  0.5005  0.0118  0.0035   \n",
       "1     1.4966 -0.0005 -0.0148  ...  1.1065  10.9003  0.5019  0.0223  0.0055   \n",
       "2     1.4436  0.0041  0.0013  ...  2.0952   9.2721  0.4958  0.0157  0.0039   \n",
       "3     1.4882 -0.0124 -0.0033  ...  1.7585   8.5831  0.4990  0.0103  0.0025   \n",
       "4     1.5031 -0.0031 -0.0072  ...  1.6597  10.9698  0.4800  0.4766  0.1045   \n",
       "...      ...     ...     ...  ...     ...      ...     ...     ...     ...   \n",
       "1562  1.3424 -0.0045 -0.0057  ...  1.4879  11.7256  0.4988  0.0143  0.0039   \n",
       "1563  1.4333 -0.0061 -0.0093  ...  1.0187  17.8379  0.4975  0.0131  0.0036   \n",
       "1564     NaN     NaN     NaN  ...  1.2237  17.7267  0.4987  0.0153  0.0041   \n",
       "1565  1.4622 -0.0072  0.0032  ...  1.7085  19.2104  0.5004  0.0178  0.0038   \n",
       "1566     NaN     NaN     NaN  ...  1.2878  22.9183  0.4987  0.0181  0.0040   \n",
       "\n",
       "          432     433     434     435       436  \n",
       "0      2.3630     NaN     NaN     NaN       NaN  \n",
       "1      4.4447  0.0096  0.0201  0.0060  208.2045  \n",
       "2      3.1745  0.0584  0.0484  0.0148   82.8602  \n",
       "3      2.0544  0.0202  0.0149  0.0044   73.8432  \n",
       "4     99.3032  0.0202  0.0149  0.0044   73.8432  \n",
       "...       ...     ...     ...     ...       ...  \n",
       "1562   2.8669  0.0068  0.0138  0.0047  203.1720  \n",
       "1563   2.6238  0.0068  0.0138  0.0047  203.1720  \n",
       "1564   3.0590  0.0197  0.0086  0.0025   43.5231  \n",
       "1565   3.5662  0.0262  0.0245  0.0075   93.4941  \n",
       "1566   3.6275  0.0117  0.0162  0.0045  137.7844  \n",
       "\n",
       "[1567 rows x 437 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4.2 A Quick Check of the Output Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "eYrOQ43XcJR3",
    "outputId": "e0873b2a-3b08-4bab-ef0d-15b88858ca44"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1562</th>\n",
       "      <td>Pass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1563</th>\n",
       "      <td>Pass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1564</th>\n",
       "      <td>Pass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1565</th>\n",
       "      <td>Pass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1566</th>\n",
       "      <td>Pass</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1567 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0\n",
       "0     Pass\n",
       "1     Pass\n",
       "2     Fail\n",
       "3     Pass\n",
       "4     Pass\n",
       "...    ...\n",
       "1562  Pass\n",
       "1563  Pass\n",
       "1564  Pass\n",
       "1565  Pass\n",
       "1566  Pass\n",
       "\n",
       "[1567 rows x 1 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nhfKXNxlSabC"
   },
   "source": [
    "### 3.5 Taking care of missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c93k7ipkSexq"
   },
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "imputer.fit(X)\n",
    "X = imputer.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 188
    },
    "colab_type": "code",
    "id": "3UgLdMS_bjq_",
    "outputId": "254af4e0-681e-47f5-aaa7-b9c6f43258e9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.03093000e+03, 2.56400000e+03, 2.18773330e+03, ...,\n",
       "        1.64749042e-02, 5.28333333e-03, 9.96700663e+01],\n",
       "       [3.09578000e+03, 2.46514000e+03, 2.23042220e+03, ...,\n",
       "        2.01000000e-02, 6.00000000e-03, 2.08204500e+02],\n",
       "       [2.93261000e+03, 2.55994000e+03, 2.18641110e+03, ...,\n",
       "        4.84000000e-02, 1.48000000e-02, 8.28602000e+01],\n",
       "       ...,\n",
       "       [2.97881000e+03, 2.37978000e+03, 2.20630000e+03, ...,\n",
       "        8.60000000e-03, 2.50000000e-03, 4.35231000e+01],\n",
       "       [2.89492000e+03, 2.53201000e+03, 2.17703330e+03, ...,\n",
       "        2.45000000e-02, 7.50000000e-03, 9.34941000e+01],\n",
       "       [2.94492000e+03, 2.45076000e+03, 2.19544440e+03, ...,\n",
       "        1.62000000e-02, 4.50000000e-03, 1.37784400e+02]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A quick check of X\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CriG6VzVSjcK"
   },
   "source": [
    "### 3.6 Encoding Categorical Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AhSpdQWeSsFh"
   },
   "source": [
    "#### 3.6.1 Encoding the Independent Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5hwuVddlSwVi"
   },
   "outputs": [],
   "source": [
    "# don't have any categorical data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DXh8oVSITIc6"
   },
   "source": [
    "#### 3.6.2 Encoding the Dependent Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XgHCShVyTOYY"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "FyhY8-gPpFCa",
    "outputId": "7f76ef29-5423-4c3e-cf69-45fbc366a997"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a quick check\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TpGqbS4TqkIR"
   },
   "source": [
    "### 3.7 Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AxjSUXFQqo-3"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "X = sc.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qb_vcgm3qZKW"
   },
   "source": [
    "### 3.8 Splitting the Dataset into the Training set and Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pXgA6CzlqbCl"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_X, test_X, train_y, test_y = train_test_split(X, y, test_size=0.2, random_state=34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 154
    },
    "colab_type": "code",
    "id": "GuwQhFdKrYTM",
    "outputId": "de1e527f-c229-4daf-e7c5-ea9d2485148d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.96046311 -0.73813734 -0.92237938 ... -0.06531583 -0.16868853\n",
      "  -0.2120265 ]\n",
      " [-0.87742151  0.5426257  -0.13250295 ...  0.60499301  0.38972867\n",
      "   3.17408017]\n",
      " [ 0.05645609 -1.51130825  1.47184855 ...  0.04829584  0.04071792\n",
      "   0.42803032]\n",
      " ...\n",
      " [-0.55464836 -0.10473817 -1.25868434 ...  1.9342495   2.16968349\n",
      "   0.21655552]\n",
      " [-0.24467179 -0.00336937 -1.42475658 ... -0.64473532 -0.79690788\n",
      "  -0.64548212]\n",
      " [-0.36283589 -0.07880372  0.55448143 ... -0.19028866 -0.02908423\n",
      "   1.62346601]]\n"
     ]
    }
   ],
   "source": [
    "print(train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "TUrX_Tvcrbi4",
    "outputId": "9a041a9b-2642-4828-fa2f-a431d7d77631"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.38726113 -0.80185131  0.15916359 ... -0.66745766 -0.65730358\n",
      "  -0.56211928]\n",
      " [-0.02413509 -0.94137368 -0.96134565 ... -1.08782082 -0.86671003\n",
      "  -0.69795783]\n",
      " [ 0.70418053  0.53813704 -0.68064891 ... -0.06531583  0.00581685\n",
      "  -0.30543175]\n",
      " ...\n",
      " [ 0.08504418  0.83962507 -1.23522968 ... -1.12190432 -1.07611647\n",
      "  -0.7688942 ]\n",
      " [ 2.27530028  0.21096393 -0.97685385 ... -0.59929066 -0.55260035\n",
      "  -0.6417691 ]\n",
      " [-0.8523729  -0.23341296 -0.28457524 ... -0.50840133 -0.51769928\n",
      "  -0.33965675]]\n"
     ]
    }
   ],
   "source": [
    "print(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "pSMHiIsWreQY",
    "outputId": "5afe91e0-9244-4bf5-ec1b-e3e092b85c08"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 1 ... 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "I_tW7H56rgtW",
    "outputId": "2a93f141-2a99-4a69-eec5-c82a3bb8d36b",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1\n",
      " 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 0 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 4 Logistic Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 4.1 Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=250)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logistic_regression_model = LogisticRegression(max_iter=250)\n",
    "\n",
    "# use the training data\n",
    "logistic_regression_model.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 4.1 Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averaged prediction accuracy = 0.9109062980030721\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(logistic_regression_model, test_X, test_y, scoring='accuracy', cv=5)\n",
    "average_score = np.average(scores)\n",
    "\n",
    "print(f\"Averaged prediction accuracy = {average_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 5 ANN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 5.1 Initialize the ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-24 21:15:53.021382: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-24 21:15:53.022031: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-10-24 21:15:53.022088: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2021-10-24 21:15:53.022134: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2021-10-24 21:15:53.022193: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2021-10-24 21:15:53.022238: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2021-10-24 21:15:53.022281: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2021-10-24 21:15:53.022324: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2021-10-24 21:15:53.022367: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2021-10-24 21:15:53.022374: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1835] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2021-10-24 21:15:53.022768: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "ann_model = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 5.2 Add input layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ann_model.add(tf.keras.layers.Dense(units=437, activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 5.3 Add hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ann_model.add(tf.keras.layers.Dense(units=200, activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 5.4 Add output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ann_model.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 5.5 Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ann_model.compile(optimizer='sgd', loss='mean_squared_error', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 5.6 Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-24 21:15:53.108289: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1377 - accuracy: 0.8476\n",
      "Epoch 2/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0706 - accuracy: 0.9346\n",
      "Epoch 3/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0654 - accuracy: 0.9346\n",
      "Epoch 4/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0637 - accuracy: 0.9346\n",
      "Epoch 5/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0629 - accuracy: 0.9346\n",
      "Epoch 6/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0624 - accuracy: 0.9346\n",
      "Epoch 7/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0620 - accuracy: 0.9346\n",
      "Epoch 8/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0617 - accuracy: 0.9346\n",
      "Epoch 9/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0615 - accuracy: 0.9346\n",
      "Epoch 10/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0613 - accuracy: 0.9346\n",
      "Epoch 11/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0611 - accuracy: 0.9346\n",
      "Epoch 12/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0610 - accuracy: 0.9346\n",
      "Epoch 13/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0608 - accuracy: 0.9346\n",
      "Epoch 14/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0606 - accuracy: 0.9346\n",
      "Epoch 15/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0604 - accuracy: 0.9346\n",
      "Epoch 16/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0602 - accuracy: 0.9346\n",
      "Epoch 17/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0600 - accuracy: 0.9346\n",
      "Epoch 18/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0598 - accuracy: 0.9346\n",
      "Epoch 19/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0596 - accuracy: 0.9346\n",
      "Epoch 20/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0593 - accuracy: 0.9346\n",
      "Epoch 21/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0591 - accuracy: 0.9346\n",
      "Epoch 22/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0588 - accuracy: 0.9346\n",
      "Epoch 23/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0585 - accuracy: 0.9346\n",
      "Epoch 24/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0582 - accuracy: 0.9346\n",
      "Epoch 25/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0579 - accuracy: 0.9346\n",
      "Epoch 26/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0577 - accuracy: 0.9346\n",
      "Epoch 27/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0574 - accuracy: 0.9354\n",
      "Epoch 28/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0571 - accuracy: 0.9354\n",
      "Epoch 29/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0567 - accuracy: 0.9354\n",
      "Epoch 30/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0564 - accuracy: 0.9354\n",
      "Epoch 31/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0561 - accuracy: 0.9354\n",
      "Epoch 32/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0558 - accuracy: 0.9354\n",
      "Epoch 33/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0554 - accuracy: 0.9354\n",
      "Epoch 34/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0550 - accuracy: 0.9354\n",
      "Epoch 35/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0547 - accuracy: 0.9354\n",
      "Epoch 36/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0542 - accuracy: 0.9354\n",
      "Epoch 37/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0538 - accuracy: 0.9354\n",
      "Epoch 38/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0534 - accuracy: 0.9354\n",
      "Epoch 39/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0530 - accuracy: 0.9354\n",
      "Epoch 40/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0525 - accuracy: 0.9354\n",
      "Epoch 41/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0521 - accuracy: 0.9362\n",
      "Epoch 42/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0516 - accuracy: 0.9370\n",
      "Epoch 43/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0510 - accuracy: 0.9370\n",
      "Epoch 44/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0505 - accuracy: 0.9370\n",
      "Epoch 45/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0498 - accuracy: 0.9370\n",
      "Epoch 46/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0491 - accuracy: 0.9377\n",
      "Epoch 47/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0484 - accuracy: 0.9393\n",
      "Epoch 48/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0477 - accuracy: 0.9393\n",
      "Epoch 49/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0471 - accuracy: 0.9393\n",
      "Epoch 50/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0465 - accuracy: 0.9393\n",
      "Epoch 51/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0459 - accuracy: 0.9409\n",
      "Epoch 52/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0453 - accuracy: 0.9409\n",
      "Epoch 53/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0447 - accuracy: 0.9409\n",
      "Epoch 54/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0441 - accuracy: 0.9409\n",
      "Epoch 55/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0436 - accuracy: 0.9417\n",
      "Epoch 56/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0430 - accuracy: 0.9417\n",
      "Epoch 57/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0424 - accuracy: 0.9425\n",
      "Epoch 58/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0418 - accuracy: 0.9433\n",
      "Epoch 59/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0412 - accuracy: 0.9441\n",
      "Epoch 60/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0407 - accuracy: 0.9465\n",
      "Epoch 61/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0401 - accuracy: 0.9481\n",
      "Epoch 62/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0395 - accuracy: 0.9497\n",
      "Epoch 63/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0390 - accuracy: 0.9497\n",
      "Epoch 64/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0384 - accuracy: 0.9537\n",
      "Epoch 65/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0379 - accuracy: 0.9537\n",
      "Epoch 66/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0374 - accuracy: 0.9553\n",
      "Epoch 67/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0369 - accuracy: 0.9553\n",
      "Epoch 68/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0364 - accuracy: 0.9553\n",
      "Epoch 69/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0358 - accuracy: 0.9561\n",
      "Epoch 70/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0353 - accuracy: 0.9561\n",
      "Epoch 71/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0348 - accuracy: 0.9569\n",
      "Epoch 72/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0343 - accuracy: 0.9577\n",
      "Epoch 73/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0338 - accuracy: 0.9577\n",
      "Epoch 74/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0333 - accuracy: 0.9577\n",
      "Epoch 75/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0328 - accuracy: 0.9585\n",
      "Epoch 76/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0324 - accuracy: 0.9609\n",
      "Epoch 77/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0319 - accuracy: 0.9609\n",
      "Epoch 78/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0315 - accuracy: 0.9617\n",
      "Epoch 79/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0310 - accuracy: 0.9633\n",
      "Epoch 80/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0306 - accuracy: 0.9633\n",
      "Epoch 81/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0301 - accuracy: 0.9633\n",
      "Epoch 82/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0297 - accuracy: 0.9641\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0293 - accuracy: 0.9649\n",
      "Epoch 84/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0288 - accuracy: 0.9649\n",
      "Epoch 85/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0284 - accuracy: 0.9649\n",
      "Epoch 86/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0280 - accuracy: 0.9705\n",
      "Epoch 87/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0276 - accuracy: 0.9697\n",
      "Epoch 88/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0272 - accuracy: 0.9713\n",
      "Epoch 89/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0268 - accuracy: 0.9713\n",
      "Epoch 90/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0264 - accuracy: 0.9713\n",
      "Epoch 91/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0260 - accuracy: 0.9713\n",
      "Epoch 92/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0256 - accuracy: 0.9721\n",
      "Epoch 93/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0252 - accuracy: 0.9713\n",
      "Epoch 94/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0248 - accuracy: 0.9737\n",
      "Epoch 95/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0244 - accuracy: 0.9753\n",
      "Epoch 96/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0240 - accuracy: 0.9753\n",
      "Epoch 97/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0236 - accuracy: 0.9761\n",
      "Epoch 98/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0232 - accuracy: 0.9769\n",
      "Epoch 99/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0229 - accuracy: 0.9769\n",
      "Epoch 100/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0225 - accuracy: 0.9785\n"
     ]
    }
   ],
   "source": [
    "fitting = ann_model.fit(train_X, train_y, batch_size=32, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.style.use('dark_background')\n",
    "\n",
    "plt.plot(fitting.history['loss'])\n",
    "plt.title('Fitting Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 5.7 Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0645 - accuracy: 0.9331\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.06448440253734589, 0.9331210255622864]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann_model.evaluate(test_X, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 6 Conclusion\n",
    "\n",
    "The average prediction accuracy of the logistic regression model on the dataset is 91%. The highest prediction accuracy\n",
    "I was able to achieve with the ANN model is 93%. I played around with additional hidden layers but these additions\n",
    "reduced the model accuracy."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "data_preprocessing_tools.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 357.5,
   "position": {
    "height": "379.5px",
    "left": "1161px",
    "right": "20px",
    "top": "122px",
    "width": "319px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "block",
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}